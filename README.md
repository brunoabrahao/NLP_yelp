# Word Algebra using Word2Vec - NLP Tutorial

An end-to-end natural language processing tutorial demonstrating word embeddings, topic modeling, and word algebra using the Yelp dataset. This tutorial was created for a Spring 2025 NLP course.

## Overview

This Jupyter notebook tutorial covers a complete NLP pipeline from raw data to advanced semantic operations, including:

- Text preprocessing with spaCy
- Phrase detection (bigrams and trigrams)
- Topic modeling with Latent Dirichlet Allocation (LDA)
- Word embeddings with Word2Vec
- Word algebra and semantic similarity
- Interactive visualizations with t-SNE and Bokeh

## Dataset

The tutorial uses the [Yelp Dataset](https://www.yelp.com/dataset), focusing on restaurant reviews:
- **4.2 million** restaurant reviews
- **60,000** restaurants
- Newline-delimited JSON format

### Obtaining the Dataset

1. Download the Yelp Dataset from [yelp.com/dataset](https://www.yelp.com/dataset)
2. Extract the compressed file
3. Place the following files in the `yelp_dataset/` directory:
   - `business.json`
   - `review.json`
   - Other files (optional): `checkin.json`, `tip.json`, `photo.json`

**Note:** The dataset files are not included in this repository due to their large size (review.json is 5.3GB).

## Installation

### Prerequisites

- Python 3.12+
- pip

### Setup

1. Clone this repository:
```bash
git clone <repository-url>
cd teaching
```

2. Create and activate a virtual environment:
```bash
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Download spaCy language model (required):
```bash
python -m spacy download en_core_web_sm
```

## Usage

1. Ensure you have the Yelp dataset in the `yelp_dataset/` directory
2. Activate the virtual environment:
```bash
source .venv/bin/activate
```

3. Launch Jupyter:
```bash
jupyter notebook lecture9_word_algebra_sp25.ipynb
```

Or use JupyterLab:
```bash
jupyter lab lecture9_word_algebra_sp25.ipynb
```

## Notebook Structure

The tutorial is organized into 176 cells (88 code + 88 markdown):

- **Cells 2-14**: Yelp Dataset - Loading and exploration
- **Cells 15-37**: spaCy - Industrial-strength NLP preprocessing
- **Cells 38-68**: Phrase Modeling - Bigram and trigram detection
- **Cells 74-108**: Topic Modeling - LDA with 50 topics
- **Cells 109-158**: Word2Vec - Word embeddings and word algebra
- **Cells 159-174**: Visualization - t-SNE dimensionality reduction
- **Cells 174-175**: Conclusion

## Key Features

### Word Algebra Examples

The notebook demonstrates semantic relationships through vector arithmetic:

```python
breakfast + lunch → brunch
taco + chinese - mexican → dumpling
filet_mignon + seafood - beef → lobster_tail
coffee + snack - drink → pastry
```

### Models Trained

- **Phrase Models**: Bigram and trigram detection
- **LDA Model**: 50 topics from 91,875-term vocabulary
- **Word2Vec Model**: 91,875 word vectors
- **t-SNE**: 2D visualization projection

### Visualizations

- Interactive LDA topic exploration with pyLDAvis
- Interactive word embedding visualization with Bokeh
- Hover tooltips for exploring semantic relationships

## Project Structure

```
teaching/
├── lecture9_word_algebra_sp25.ipynb  # Main tutorial notebook
├── yelp_dataset/                      # Yelp data (not in repo)
│   ├── business.json                  # Business records
│   ├── review.json                    # Review text (5.3GB)
│   └── intermediate/                  # Generated files
├── requirements.txt                   # Python dependencies
├── CLAUDE.md                          # Developer documentation
├── .gitignore                         # Git ignore rules
└── README.md                          # This file
```

## Technical Details

### Memory Efficiency

The notebook uses streaming iterators (e.g., `gensim.LineSentence`) to process the large dataset without loading everything into RAM simultaneously.

### Processing Pipeline

1. **Data Filtering**: Extract restaurant reviews from full dataset
2. **Tokenization**: spaCy-based text processing
3. **Phrase Detection**: Statistical collocation detection
4. **Lemmatization**: Reduce words to base forms
5. **Topic Modeling**: Discover latent themes in reviews
6. **Word Embeddings**: Train semantic word vectors
7. **Visualization**: Interactive exploration of results

### Intermediate Files

The notebook generates 12 intermediate files during execution (stored in `yelp_dataset/intermediate/`):

1. Processed text files (unigrams, bigrams, trigrams)
2. Gensim models (dictionary, LDA, Word2Vec)
3. Visualization data (pyLDAvis, t-SNE projections)

These files are excluded from version control but can be regenerated by running the notebook.

## Dependencies

- **spacy** ≥3.0 - NLP preprocessing
- **gensim** ≥4.0 - Topic modeling and word embeddings
- **pandas** ≥1.0 - Data manipulation
- **numpy** ≥1.20 - Numerical computing
- **bokeh** ≥3.4 - Interactive visualizations
- **pyLDAvis** ≥3.3 - LDA visualization
- **jupyter** ≥1.0 - Notebook environment

See `requirements.txt` for complete dependency list.

## Contributing

This is an educational tutorial. If you find issues or have suggestions:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## License

This tutorial is provided for educational purposes. Please refer to the [Yelp Dataset License](https://www.yelp.com/dataset) for dataset usage terms.

## Acknowledgments

- Yelp for providing the dataset
- The spaCy and gensim communities for excellent NLP tools
- Students and instructors who have contributed feedback

## Support

For questions or issues:
- Open an issue on GitHub
- Consult the `CLAUDE.md` file for developer documentation
- Check the notebook's markdown cells for detailed explanations

---

**Course**: Spring 2025 NLP
**Topic**: Word Algebra and Word Embeddings
**Focus**: End-to-end NLP pipeline with real-world data
